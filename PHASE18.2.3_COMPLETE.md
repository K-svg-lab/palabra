# Phase 18.2.3 Complete: A/B Testing Framework
**Feature Validation with Data-Driven Decisions**

**Completed:** February 10, 2026  
**Status:** ‚úÖ COMPLETE  
**Duration:** < 1 day (as planned: 5-6 days)  
**Priority:** High  
**Effort:** High

---

## üéØ **Executive Summary**

Successfully implemented a complete **A/B Testing Framework** for validating Phase 18 features with real user data. This enables data-driven decision making about which features to keep, iterate, or remove.

### **Key Achievement**
Built a production-ready A/B testing system that:
- ‚úÖ Randomly assigns users to experiment groups on signup
- ‚úÖ Controls feature visibility via feature flags
- ‚úÖ Tracks retention metrics by cohort
- ‚úÖ Calculates statistical significance (chi-square test)
- ‚úÖ Provides admin dashboard for monitoring results
- ‚úÖ Supports sequential testing (one experiment at a time)

---

## ‚ú® **What Was Built**

### **1. A/B Test Configuration System** ‚öôÔ∏è
**File:** `lib/config/ab-tests.ts` (450 lines)

**4 Experiments Defined:**

#### **Test 1: AI-Generated Examples Validation**
- **Hypothesis:** Users with AI examples will show 15-20% higher 30-day retention
- **Groups:** Control (no AI examples) vs Treatment (AI examples)
- **Duration:** 90 days
- **Sample Size:** 200+ users per group
- **Metrics:** Day 7/30/90 retention, accuracy, words added

#### **Test 2: Retrieval Variation Validation**
- **Hypothesis:** 5 retrieval methods will show 20%+ higher retention vs traditional only
- **Groups:** Traditional only vs 5 varied methods
- **Duration:** 90 days
- **Sample Size:** 200+ users per group
- **Metrics:** Day 30/90 retention, accuracy, session completion

#### **Test 3: Interleaved Practice Validation**
- **Hypothesis:** Interleaved practice will show 30-40% higher retention (research: 43%)
- **Groups:** Blocked practice vs Interleaved practice
- **Duration:** 90 days
- **Sample Size:** 200+ users per group
- **Metrics:** Day 30/90 retention, accuracy, study time

#### **Test 4: Deep Learning Mode Validation**
- **Hypothesis:** Deep learning mode will show 10-15% better retention (research: d=0.71)
- **Groups:** Standard review vs Deep learning enabled
- **Duration:** 90 days
- **Sample Size:** 200+ users per group
- **Metrics:** Day 30/90 retention, accuracy, study time

**Feature Flags Structure:**
```typescript
interface FeatureFlags {
  aiExamples: boolean;
  retrievalVariation: boolean;
  interleavedPractice: boolean;
  interferenceDetection: boolean;
  deepLearningMode: boolean;
}
```

**Test Constraints:**
- Only ONE test active at a time (prevents confounding)
- 50/50 split (control vs treatment)
- Minimum 200 users per group
- Minimum 30 days duration (for Day 30 retention)

---

### **2. User Assignment Service** üé≤
**File:** `lib/services/ab-test-assignment.ts` (300 lines)

**Key Functions:**

#### **assignUserToExperiments(userId)**
- Called when user signs up or first visits
- Randomly assigns to control or treatment group (50/50)
- Updates UserCohort with experimentGroup and featureFlags

#### **getUserFeatureFlags(userId)**
- Returns user's assigned feature flags
- Auto-assigns if user not in cohort yet
- Used by components to conditionally render features

#### **hasFeature(userId, feature)**
- Quick check if specific feature is enabled
- Used for granular feature gating

#### **selectGroup(groups)**
- Weighted random selection based on allocation
- Ensures even distribution across groups

**Assignment Algorithm:**
```typescript
function selectGroup(groups: ABTestGroup[]): ABTestGroup {
  const random = Math.random(); // 0.0 - 1.0
  let cumulative = 0;

  for (const group of groups) {
    cumulative += group.allocation; // e.g., 0.5
    if (random < cumulative) {
      return group; // Assigned!
    }
  }
  
  return groups[0]; // Fallback
}
```

**Example:**
- Random = 0.23 ‚Üí Control (0.23 < 0.5)
- Random = 0.67 ‚Üí Treatment (0.67 >= 0.5)

---

### **3. Feature Flag Hook** ‚öõÔ∏è
**File:** `lib/hooks/use-feature-flags.ts` (200 lines)

**React Hook:**
```typescript
const { flags, hasFeature, loading } = useFeatureFlags();

if (hasFeature('retrievalVariation')) {
  // Show all 5 review methods
} else {
  // Show traditional method only
}
```

**Component Wrapper:**
```tsx
<FeatureGate feature="aiExamples" fallback={<BasicLookup />}>
  <AIGeneratedExamples word={word} />
</FeatureGate>
```

**Features:**
- ‚úÖ Automatic feature flag loading from server
- ‚úÖ Guest user support (returns default features)
- ‚úÖ Loading states
- ‚úÖ Multiple feature checks (`hasAllFeatures`, `hasAnyFeature`)

---

### **4. API Endpoints** üîå

#### **GET /api/user/feature-flags**
**File:** `app/api/user/feature-flags/route.ts`

Returns feature flags for authenticated user.

**Response:**
```json
{
  "flags": {
    "aiExamples": true,
    "retrievalVariation": false,
    "interleavedPractice": true,
    "interferenceDetection": true,
    "deepLearningMode": false
  },
  "isGuest": false
}
```

#### **GET /api/analytics/ab-test-results?testId=xxx**
**File:** `app/api/analytics/ab-test-results/route.ts`

Admin-only endpoint returning A/B test results with statistical analysis.

**Response:**
```json
{
  "test": {
    "id": "ai-examples-validation",
    "name": "AI-Generated Examples Impact",
    "startDate": "2026-02-15T00:00:00.000Z",
    "endDate": "2026-05-15T00:00:00.000Z"
  },
  "groups": [
    {
      "groupId": "control",
      "groupName": "Control Group",
      "userCount": 245,
      "day7Retention": 65.3,
      "day30Retention": 42.0,
      "day90Retention": 28.5,
      "avgAccuracy": 78.2,
      "lift": 0.0
    },
    {
      "groupId": "treatment",
      "groupName": "AI Examples Group",
      "userCount": 238,
      "day7Retention": 72.1,
      "day30Retention": 52.5,
      "avgAccuracy": 82.6,
      "lift": +10.5
    }
  ],
  "pValue": 0.0234,
  "significant": true,
  "readyForAnalysis": true,
  "daysRunning": 92
}
```

**Statistical Analysis:**
- Chi-square test for retention differences
- Two-tailed test, Œ± = 0.05
- P-value < 0.05 = statistically significant
- Lift calculation (treatment - control)

---

### **5. Admin Dashboard** üìä
**File:** `app/(dashboard)/admin/ab-tests/page.tsx` (550 lines)

**Features:**
- ‚úÖ Real-time A/B test results
- ‚úÖ Retention comparison table
- ‚úÖ Statistical significance indicator
- ‚úÖ Lift calculations (% improvement)
- ‚úÖ Sample size and duration tracking
- ‚úÖ Ready for analysis indicator
- ‚úÖ Auto-refresh every 5 minutes
- ‚úÖ Planned tests preview

**UI Components:**
- **Active Test Card**: Shows live results with metrics
- **Results Table**: Side-by-side comparison of control vs treatment
- **Significance Badge**: Green checkmark if p < 0.05
- **Warning Banner**: Shows if sample size or duration insufficient
- **Planned Tests**: Preview of upcoming experiments

**Access Control:**
- Admin-only (checks `process.env.ADMIN_EMAIL`)
- Redirects non-admins to homepage
- Future: Add `isAdmin` field to User model

---

### **6. Comprehensive Tests** üß™
**File:** `lib/services/__tests__/ab-test-assignment.test.ts` (500 lines)

**Test Coverage:**
- ‚úÖ Test Structure (5 tests)
  - Valid test definitions
  - 2 groups per test (control + treatment)
  - Valid allocations (sum to 1.0)
  - Equal 50/50 split
  - No overlapping test periods
  
- ‚úÖ Feature Flags (3 tests)
  - Default features validation
  - Features defined for each group
  - ONE feature difference (isolate variable)
  
- ‚úÖ Metrics (2 tests)
  - Valid metric types
  - Display names
  
- ‚úÖ Test Utilities (4 tests)
  - Get active test
  - Get test by ID
  - Allocation validation
  
- ‚úÖ Random Assignment (2 tests)
  - Even distribution (50/50)
  - Correct group selection
  
- ‚úÖ Statistical Significance (3 tests)
  - Minimum sample size (200+)
  - Minimum duration (30+ days)
  - Chi-square calculation
  
- ‚úÖ Business Validation (3 tests)
  - All features tested
  - Realistic hypotheses
  - Reasonable durations
  
- ‚úÖ Cohort Tracking (3 tests)
  - ISO week calculation
  - Year-month format
  - Signup date tracking

**Total: 25 test cases** ‚úÖ All passing

---

## üìä **Technical Implementation**

### **Random Assignment Algorithm**

**Weighted Random Selection:**
```typescript
// 50% Control, 50% Treatment
const random = Math.random(); // 0.0 - 1.0

if (random < 0.5) {
  return controlGroup; // 50% probability
} else {
  return treatmentGroup; // 50% probability
}
```

**Cumulative Distribution:**
For unequal allocations (e.g., 30/70 split):
```typescript
let cumulative = 0;
for (const group of groups) {
  cumulative += group.allocation;
  if (random < cumulative) {
    return group;
  }
}
```

### **Statistical Significance (Chi-Square Test)**

**Null Hypothesis:** No difference between groups  
**Alternative Hypothesis:** Significant difference exists

**Formula:**
```typescript
// Calculate pooled proportion
const pooledP = (x1 + x2) / (n1 + n2);

// Calculate standard error
const se = sqrt(pooledP * (1 - pooledP) * (1/n1 + 1/n2));

// Calculate z-score
const z = abs(p1 - p2) / se;

// Convert to p-value (two-tailed)
const pValue = 2 * (1 - normalCDF(z));

// Significant if p < 0.05
const significant = pValue < 0.05;
```

**Example:**
- Control: 200 users, 60% retention (120 users)
- Treatment: 200 users, 75% retention (150 users)
- Pooled: 67.5% retention
- Z-score: 3.2 (large difference)
- P-value: 0.0014 (highly significant)
- **Result:** Treatment significantly better ‚úÖ

### **Cohort Tracking**

**Cohort Definition:** Users who signed up on the same date/week/month

**Fields in UserCohort:**
```typescript
cohortDate: Date;        // Signup date
cohortWeek: string;      // ISO week (e.g., "2026-W07")
cohortMonth: string;     // Year-month (e.g., "2026-02")
experimentGroup: string; // "control" or "treatment"
featureFlags: Json;      // Assigned features

// Retention tracking
day1Active: boolean;
day7Active: boolean;
day30Active: boolean;
day90Active: boolean;
```

**ISO Week Calculation:**
```typescript
function getISOWeek(date: Date): string {
  const d = new Date(date);
  d.setDate(d.getDate() + 4 - (d.getDay() || 7));
  
  const yearStart = new Date(d.getFullYear(), 0, 1);
  const weekNo = Math.ceil(
    (((d - yearStart) / 86400000) + 1) / 7
  );
  
  return `${d.getFullYear()}-W${weekNo.toString().padStart(2, '0')}`;
}
```

---

## üìà **Expected Impact**

### **Business Value**
- **Data-Driven Decisions**: Know which features actually improve retention
- **Risk Mitigation**: Test before full rollout
- **Cost Optimization**: Remove features that don't work
- **User Trust**: Only ship validated features

### **Example Outcomes**

**Scenario 1: Feature Works**
- Control: 42% Day 30 retention
- Treatment: 52% Day 30 retention
- **Lift:** +10% (p = 0.023, significant)
- **Decision:** ‚úÖ Roll out to all users

**Scenario 2: Feature Doesn't Work**
- Control: 42% Day 30 retention
- Treatment: 41% Day 30 retention
- **Lift:** -1% (p = 0.85, not significant)
- **Decision:** ‚ùå Remove feature, save costs

**Scenario 3: Needs More Data**
- Control: 42% Day 30 retention (50 users)
- Treatment: 48% Day 30 retention (45 users)
- **Lift:** +6% (p = 0.47, not significant)
- **Decision:** ‚è≥ Wait for 200+ users per group

### **ROI Calculation**

**Example: AI Examples Feature**
- Cost: $50/month (OpenAI API)
- Baseline retention: 40%
- With AI examples: 52%
- **Lift:** +12% = 12 more retained users per 100 signups
- **LTV per user:** $10/month
- **Additional revenue:** 12 users √ó $10 = $120/month
- **Net profit:** $120 - $50 = **$70/month** (140% ROI)

---

## üóÇÔ∏è **Files Created/Modified**

### **Created (7 files, ~2,200 lines)**
1. `lib/config/ab-tests.ts` - Test definitions (450 lines)
2. `lib/services/ab-test-assignment.ts` - User assignment (300 lines)
3. `lib/hooks/use-feature-flags.ts` - React hook (200 lines)
4. `app/api/user/feature-flags/route.ts` - Feature flags API (100 lines)
5. `app/api/analytics/ab-test-results/route.ts` - Results API (450 lines)
6. `app/(dashboard)/admin/ab-tests/page.tsx` - Admin dashboard (550 lines)
7. `lib/services/__tests__/ab-test-assignment.test.ts` - Tests (500 lines)

### **Modified (1 file)**
1. `lib/backend/prisma/schema.prisma` - UserCohort already exists (no changes needed)

---

## ‚úÖ **Acceptance Criteria**

All acceptance criteria met:

- [x] Users randomly assigned to control/treatment on signup ‚úÖ
- [x] Assignment is stable (user stays in same group) ‚úÖ
- [x] Feature flags control visibility of experimental features ‚úÖ
- [x] React hook provides easy feature checking ‚úÖ
- [x] Admin dashboard shows real-time A/B test results ‚úÖ
- [x] Statistical significance calculated (chi-square test) ‚úÖ
- [x] Only ONE test active at a time (prevents confounding) ‚úÖ
- [x] Minimum sample size enforced (200+ per group) ‚úÖ
- [x] Tests run for minimum duration (30+ days) ‚úÖ

---

## üöÄ **Next Steps**

### **Immediate**
- [ ] Set ADMIN_EMAIL environment variable
- [ ] Activate first A/B test (set `active: true` in config)
- [ ] Monitor user assignment in UserCohort table
- [ ] Wait for 200+ users per group

### **Phase 18.2.4: Admin Analytics Dashboard**
- [ ] Aggregate metrics across all users
- [ ] Cohort retention charts
- [ ] Funnel analysis
- [ ] User engagement metrics
- [ ] Integration with A/B test results

### **Future Enhancements**
- [ ] Add `isAdmin` field to User model
- [ ] Multi-armed bandit testing (dynamic allocation)
- [ ] Bayesian A/B testing
- [ ] Sequential testing with early stopping
- [ ] Segment-based analysis (by language level, device, etc.)

---

## üìù **Usage Guide**

### **1. Define a New Experiment**

Edit `lib/config/ab-tests.ts`:

```typescript
{
  id: 'my-new-feature-test',
  name: 'New Feature Test',
  description: 'Test if new feature improves retention',
  hypothesis: 'Feature X will increase retention by 15%',
  startDate: new Date('2026-03-01'),
  endDate: new Date('2026-05-30'),
  minimumSampleSize: 200,
  minimumDuration: 30,
  groups: [
    {
      id: 'control',
      name: 'Control',
      description: 'Without feature X',
      allocation: 0.5,
      features: {
        ...DEFAULT_FEATURES,
        newFeature: false, // ‚ùå Feature OFF
      },
    },
    {
      id: 'treatment',
      name: 'Treatment',
      description: 'With feature X',
      allocation: 0.5,
      features: {
        ...DEFAULT_FEATURES,
        newFeature: true, // ‚úÖ Feature ON
      },
    },
  ],
  metrics: ['day30Retention', 'avgAccuracy'],
  active: true, // ‚úÖ Activate test
}
```

### **2. Use Feature Flags in Components**

```tsx
import { useFeatureFlags } from '@/lib/hooks/use-feature-flags';

export function MyComponent() {
  const { hasFeature, loading } = useFeatureFlags();

  if (loading) return <LoadingSpinner />;

  return (
    <div>
      {hasFeature('newFeature') ? (
        <NewFeatureUI />
      ) : (
        <OldFeatureUI />
      )}
    </div>
  );
}
```

### **3. Monitor Results**

1. Go to `/admin/ab-tests`
2. View live retention metrics
3. Check statistical significance
4. Wait for "Ready for Analysis" badge (200+ users, 30+ days)
5. Make decision based on data

### **4. Roll Out or Roll Back**

**If significant improvement:**
```typescript
// Update DEFAULT_FEATURES
export const DEFAULT_FEATURES: FeatureFlags = {
  ...
  newFeature: true, // ‚úÖ Roll out to all users
};

// Deactivate test
active: false,
```

**If no improvement or negative:**
```typescript
// Remove feature code
// Keep newFeature: false in DEFAULT_FEATURES
// Deactivate test
active: false,
```

---

## üìö **Research References**

1. **Kohavi, R., Deng, A., Frasca, B., Walker, T., Xu, Y., & Pohlmann, N. (2013)**  
   "Online controlled experiments at large scale"  
   *ACM SIGKDD Conference*  
   Best practices for A/B testing at scale

2. **Deng, A., Xu, Y., Kohavi, R., & Walker, T. (2013)**  
   "Improving the sensitivity of online controlled experiments by utilizing pre-experiment data"  
   *WSDM '13*  
   Statistical power and sample size calculations

3. **Kohavi, R., Tang, D., & Xu, Y. (2020)**  
   "Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing"  
   *Cambridge University Press*  
   Comprehensive guide to A/B testing methodology

---

## üèÜ **Achievement**

**Phase 18.2.3 complete in < 1 day** (ahead of 5-6 day estimate)

**Impact:**
- Data-driven feature validation
- Risk-free experimentation
- Optimized user experience
- Cost-effective development

**Alignment:**
- ‚úÖ Rigorous methodology (chi-square test, p < 0.05)
- ‚úÖ Scalable architecture (supports multiple experiments)
- ‚úÖ Production-ready (comprehensive tests, admin dashboard)
- ‚úÖ User-friendly (automatic assignment, seamless UX)

---

**Status:** ‚úÖ Task 18.2.3 COMPLETE  
**Next:** Task 18.2.4 - Admin Analytics Dashboard  
**Phase 18.2 Progress:** 75% complete (3/4 tasks)

**Last Updated:** February 10, 2026, 18:30 PST  
**Completed By:** AI Assistant
